{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23f08af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 1127 개의 학습 샘플 생성됨\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ============================================================\n",
    "# 1. IoU 계산 (2D 바운딩 박스)\n",
    "# ============================================================\n",
    "def iou_2d(boxA, boxB):\n",
    "    \"\"\"\n",
    "    boxA, boxB: [x1,y1,x2,y2]\n",
    "    \"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
    "    return iou\n",
    "\n",
    "# ============================================================\n",
    "# 2. KITTI 파일 로더 (prediction & label 공통)\n",
    "# ============================================================\n",
    "def load_kitti_file(path, with_score=True):\n",
    "    \"\"\"\n",
    "    path: KITTI label or prediction txt\n",
    "    return: list of dicts [{'box2d','box3d','score'}]\n",
    "    \"\"\"\n",
    "    dets = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 15:  # invalid line\n",
    "                continue\n",
    "            cls = parts[0]\n",
    "            if cls != 'Car':  # Car만 처리\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(float, parts[4:8])\n",
    "            h, w, l = map(float, parts[8:11])\n",
    "            x, y, z, ry = map(float, parts[11:15])\n",
    "            score = float(parts[15]) if with_score and len(parts) > 15 else 1.0\n",
    "            dets.append({\n",
    "                \"box2d\":[x1,y1,x2,y2],\n",
    "                \"box3d\":[x,y,z,w,h,l,ry],\n",
    "                \"score\":score\n",
    "            })\n",
    "    return dets\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Keypoint set 로더 (예시: json or npy → KITTI와 동일 구조로 변환했다고 가정)\n",
    "# ============================================================\n",
    "import json\n",
    "def load_keypoint_json(json_path, image_id):\n",
    "    \"\"\"\n",
    "    json_path: keypoints_with_theta_pred_train.json\n",
    "    image_id:  \"000123\" (확장자 제거)\n",
    "    return: [{'box2d','keypoints','ry'}]\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    kp_sets = []\n",
    "    for obj in data:\n",
    "        # image_id 매칭\n",
    "        if obj[\"image_id\"].split('.')[0] != image_id:\n",
    "            continue\n",
    "        kp_sets.append({\n",
    "            \"box2d\": obj[\"crop_bbox\"],                # [x1,y1,x2,y2]\n",
    "            \"keypoints\": np.array(obj[\"keypoints\"]),  # (K,2)\n",
    "            \"ry\": obj[\"theta\"]\n",
    "        })\n",
    "    return kp_sets\n",
    "\n",
    "# ============================================================\n",
    "# 4. 매칭 함수 no 3d박스 iou\n",
    "# ============================================================\n",
    "# def build_samples(output_dir, kp_json_path, label_dir, iou_thresh=0.8):\n",
    "#     samples = []\n",
    "#     out_files = sorted(glob.glob(os.path.join(output_dir, \"*.txt\")))\n",
    "\n",
    "#     for out_path in out_files:\n",
    "#         image_id = os.path.splitext(os.path.basename(out_path))[0]\n",
    "#         label_path = os.path.join(label_dir, image_id + \".txt\")\n",
    "\n",
    "#         if not os.path.exists(label_path):\n",
    "#             continue\n",
    "\n",
    "#         outputs = load_kitti_file(out_path, with_score=True)\n",
    "#         kp_sets = load_keypoint_json(kp_json_path, image_id)  # JSON에서 해당 image_id 가져오기\n",
    "#         labels  = load_kitti_file(label_path, with_score=False)\n",
    "\n",
    "#         for out in outputs:\n",
    "#             for kp in kp_sets:\n",
    "#                 iou = iou_2d(out[\"box2d\"], kp[\"box2d\"])\n",
    "#                 if iou >= iou_thresh:\n",
    "#                     # label에서 가장 IoU 큰 것 선택\n",
    "#                     gt = max(labels, key=lambda g: iou_2d(out[\"box2d\"], g[\"box2d\"]))\n",
    "#                     samples.append({\n",
    "#                         \"init_3d\": np.array(out[\"box3d\"], dtype=np.float32),\n",
    "#                         \"keypoints\": np.array(kp[\"keypoints\"], dtype=np.float32).flatten(),\n",
    "#                         \"ry_keypoint\": np.array([kp[\"ry\"]], dtype=np.float32),\n",
    "#                         \"gt_3d\": np.array(gt[\"box3d\"], dtype=np.float32),\n",
    "#                     })\n",
    "#     return samples\n",
    "\n",
    "\n",
    "\n",
    "def bev_iou(box1, box2):\n",
    "    \"\"\"두 3D box의 BEV IoU 계산 (KITTI x,z 평면 기준).\"\"\"\n",
    "    from shapely.geometry import Polygon\n",
    "    x, y, z, w, h, l, ry = box1\n",
    "    cosa, sina = np.cos(ry), np.sin(ry)\n",
    "    dx, dz = w/2, l/2\n",
    "    corners = np.array([\n",
    "        [ dx,  dz],\n",
    "        [ dx, -dz],\n",
    "        [-dx, -dz],\n",
    "        [-dx,  dz]\n",
    "    ])\n",
    "    rot = np.array([[cosa, -sina],[sina, cosa]])\n",
    "    corners = corners @ rot.T\n",
    "    corners += np.array([x, z])\n",
    "    poly1 = Polygon(corners)\n",
    "\n",
    "    x, y, z, w, h, l, ry = box2\n",
    "    cosa, sina = np.cos(ry), np.sin(ry)\n",
    "    dx, dz = w/2, l/2\n",
    "    corners = np.array([\n",
    "        [ dx,  dz],\n",
    "        [ dx, -dz],\n",
    "        [-dx, -dz],\n",
    "        [-dx,  dz]\n",
    "    ])\n",
    "    rot = np.array([[cosa, -sina],[sina, cosa]])\n",
    "    corners = corners @ rot.T\n",
    "    corners += np.array([x, z])\n",
    "    poly2 = Polygon(corners)\n",
    "\n",
    "    inter = poly1.intersection(poly2).area\n",
    "    union = poly1.union(poly2).area\n",
    "    return inter / (union + 1e-6)\n",
    "\n",
    "\n",
    "def build_samples(output_dir, kp_json_path, label_dir, iou_thresh=0.8, iou3d_thresh=0.3):\n",
    "    samples = []\n",
    "    out_files = sorted(glob.glob(os.path.join(output_dir, \"*.txt\")))\n",
    "\n",
    "    for out_path in out_files:\n",
    "        image_id = os.path.splitext(os.path.basename(out_path))[0]\n",
    "        label_path = os.path.join(label_dir, image_id + \".txt\")\n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "\n",
    "        outputs = load_kitti_file(out_path, with_score=True)\n",
    "        kp_sets = load_keypoint_json(kp_json_path, image_id)\n",
    "        labels  = load_kitti_file(label_path, with_score=False)\n",
    "\n",
    "        for out in outputs:\n",
    "            for kp in kp_sets:\n",
    "                iou2d = iou_2d(out[\"box2d\"], kp[\"box2d\"])\n",
    "                if iou2d >= iou_thresh:\n",
    "                    # label 중에서 3D IoU ≥ iou3d_thresh 조건 만족하는 것만 고려\n",
    "                    valid_gts = [g for g in labels if bev_iou(out[\"box3d\"], g[\"box3d\"]) >= iou3d_thresh]\n",
    "                    if len(valid_gts) == 0:\n",
    "                        continue  # 3D IoU ≥ 0.3 만족하는 GT 없으면 skip\n",
    "                    gt = max(valid_gts, key=lambda g: bev_iou(out[\"box3d\"], g[\"box3d\"]))\n",
    "                    samples.append({\n",
    "                        \"init_3d\": np.array(out[\"box3d\"], dtype=np.float32),\n",
    "                        \"keypoints\": np.array(kp[\"keypoints\"], dtype=np.float32).flatten(),\n",
    "                        \"ry_keypoint\": np.array([kp[\"ry\"]], dtype=np.float32),\n",
    "                        \"gt_3d\": np.array(gt[\"box3d\"], dtype=np.float32),\n",
    "                    })\n",
    "    return samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Dataset & Model (앞에서 정의한 그대로)\n",
    "# ============================================================\n",
    "class RefineDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "        return {\n",
    "            \"init_3d\": torch.tensor(s[\"init_3d\"]),\n",
    "            \"keypoints\": torch.tensor(s[\"keypoints\"]),\n",
    "            \"ry_keypoint\": torch.tensor(s[\"ry_keypoint\"]),\n",
    "            \"gt_3d\": torch.tensor(s[\"gt_3d\"]),\n",
    "        }\n",
    "\n",
    "class OutputKeypointRegressor(nn.Module):\n",
    "    def __init__(self, kp_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        input_dim = 7 + kp_dim + 1\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, 7)\n",
    "\n",
    "    def forward(self, init_3d, keypoints, yaw):\n",
    "        x = torch.cat([init_3d, keypoints, yaw], dim=-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        delta = self.fc_out(x)\n",
    "        return delta\n",
    "\n",
    "def train_regressor(samples, kp_dim=24, epochs=10, batch_size=16, lr=1e-3,\n",
    "                    save_path=\"../outputs/regressor_best.pth\"):\n",
    "    dataset = RefineDataset(samples)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    model = OutputKeypointRegressor(kp_dim=kp_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            init_3d = batch[\"init_3d\"]\n",
    "            keypoints = batch[\"keypoints\"]\n",
    "            ry_keypoint = batch[\"ry_keypoint\"]\n",
    "            gt_3d = batch[\"gt_3d\"]\n",
    "\n",
    "            delta_gt = gt_3d - init_3d\n",
    "            delta_pred = model(init_3d, keypoints, ry_keypoint)\n",
    "\n",
    "            loss = F.smooth_l1_loss(delta_pred, delta_gt)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"[Epoch {epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # ✅ Best 모델 저장\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"  ↳ 새로운 best 모델 저장됨: {save_path} (loss={best_loss:.4f})\")\n",
    "\n",
    "    print(\"학습 완료. Best Loss =\", best_loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resume_training(samples, kp_dim, epochs=10, batch_size=16, lr=1e-3,\n",
    "                    resume_path=\"../outputs/regressor_best.pth\",\n",
    "                    save_path=\"../outputs/regressor_best.pth\"):\n",
    "    dataset = RefineDataset(samples)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    model = OutputKeypointRegressor(kp_dim=kp_dim)\n",
    "\n",
    "    # ✅ 기존 checkpoint 불러오기\n",
    "    if os.path.exists(resume_path):\n",
    "        model.load_state_dict(torch.load(resume_path))\n",
    "        print(f\"기존 모델 로드 완료: {resume_path}\")\n",
    "    else:\n",
    "        print(\"⚠️ resume_path 에 파일이 없어 새로 학습을 시작합니다.\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            init_3d = batch[\"init_3d\"]\n",
    "            keypoints = batch[\"keypoints\"]\n",
    "            ry_keypoint = batch[\"ry_keypoint\"]\n",
    "            gt_3d = batch[\"gt_3d\"]\n",
    "\n",
    "            delta_gt = gt_3d - init_3d\n",
    "            delta_pred = model(init_3d, keypoints, ry_keypoint)\n",
    "\n",
    "            loss = F.smooth_l1_loss(delta_pred, delta_gt)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"[Resume Epoch {epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # ✅ best 저장\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"  ↳ 새로운 best 모델 저장됨: {save_path} (loss={best_loss:.4f})\")\n",
    "\n",
    "    print(\"추가 학습 완료. Best Loss =\", best_loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 실행 예시\n",
    "output_dir = \"../dataset/merge_output_train\"         # detector 결과 (KITTI txt)\n",
    "kp_json_path = \"../dataset/keypoints_with_theta_pred_train.json\"  # keypoint + theta JSON\n",
    "label_dir    = \"../dataset/label_2_train\"         # KITTI GT labels\n",
    "\n",
    "samples = build_samples(output_dir, kp_json_path, label_dir, iou_thresh=0.75)\n",
    "print(f\"총 {len(samples)} 개의 학습 샘플 생성됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daebaa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/10] Loss: 2.6477\n",
      "  ↳ 새로운 best 모델 저장됨: ../outputs/regressor_best.pth (loss=2.6477)\n",
      "[Epoch 2/10] Loss: 0.6659\n",
      "  ↳ 새로운 best 모델 저장됨: ../outputs/regressor_best.pth (loss=0.6659)\n",
      "[Epoch 3/10] Loss: 0.5232\n",
      "  ↳ 새로운 best 모델 저장됨: ../outputs/regressor_best.pth (loss=0.5232)\n",
      "[Epoch 4/10] Loss: 0.3914\n",
      "  ↳ 새로운 best 모델 저장됨: ../outputs/regressor_best.pth (loss=0.3914)\n",
      "[Epoch 5/10] Loss: 0.2278\n",
      "  ↳ 새로운 best 모델 저장됨: ../outputs/regressor_best.pth (loss=0.2278)\n",
      "[Epoch 6/10] Loss: 0.3674\n",
      "[Epoch 7/10] Loss: 0.3153\n",
      "[Epoch 8/10] Loss: 0.2824\n",
      "[Epoch 9/10] Loss: 0.1967\n",
      "  ↳ 새로운 best 모델 저장됨: ../outputs/regressor_best.pth (loss=0.1967)\n",
      "[Epoch 10/10] Loss: 0.1931\n",
      "  ↳ 새로운 best 모델 저장됨: ../outputs/regressor_best.pth (loss=0.1931)\n",
      "학습 완료. Best Loss = 0.19308086054425844\n"
     ]
    }
   ],
   "source": [
    "#학습 & best.pth 저장\n",
    "model = train_regressor(\n",
    "    samples,\n",
    "    kp_dim=len(samples[0][\"keypoints\"]),\n",
    "    epochs=10,\n",
    "    save_path=\"../outputs/regressor_best.pth\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 기존 모델 이어서 학습\n",
    "# model = resume_training(\n",
    "#     samples,\n",
    "#     kp_dim=len(samples[0][\"keypoints\"]),\n",
    "#     epochs=500,   # 추가 학습 epoch\n",
    "#     resume_path=\"../outputs/regressor_best.pth\",\n",
    "#     save_path=\"../outputs/regressor_best.pth\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# def refine_outputs(model, output_dir, kp_json_path, save_dir, iou_thresh=0.5):\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     out_files = sorted(glob.glob(os.path.join(output_dir, \"*.txt\")))\n",
    "\n",
    "#     for out_path in out_files:\n",
    "#         image_id = os.path.splitext(os.path.basename(out_path))[0]\n",
    "\n",
    "#         # 원래 detection 결과\n",
    "#         outputs = load_kitti_file(out_path, with_score=True)\n",
    "#         if len(outputs) == 0:\n",
    "#             # 비어있으면 빈 txt 저장\n",
    "#             open(os.path.join(save_dir, image_id + \".txt\"), \"w\").close()\n",
    "#             continue\n",
    "\n",
    "#         # keypoints set\n",
    "#         kp_sets = load_keypoint_json(kp_json_path, image_id)\n",
    "\n",
    "#         refined_dets = []\n",
    "#         for out in outputs:\n",
    "#             best_match = None\n",
    "#             best_iou = 0.0\n",
    "#             for kp in kp_sets:\n",
    "#                 iou = iou_2d(out[\"box2d\"], kp[\"box2d\"])\n",
    "#                 if iou > best_iou:\n",
    "#                     best_iou = iou\n",
    "#                     best_match = kp\n",
    "\n",
    "#             if best_match is not None and best_iou >= iou_thresh:\n",
    "#                 # refine 적용\n",
    "#                 init_3d = torch.tensor(out[\"box3d\"], dtype=torch.float32).unsqueeze(0)\n",
    "#                 keypoints = torch.tensor(best_match[\"keypoints\"], dtype=torch.float32).flatten().unsqueeze(0)\n",
    "#                 ry_keypoint = torch.tensor([best_match[\"ry\"]], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "#                 delta = model(init_3d, keypoints, ry_keypoint).detach().cpu().numpy()[0]\n",
    "#                 refined_box = init_3d.numpy()[0] + delta*0.5\n",
    "#             else:\n",
    "#                 # 매칭 안되면 그대로 사용\n",
    "#                 refined_box = out[\"box3d\"]\n",
    "\n",
    "#             refined_dets.append({\n",
    "#                 \"cls\": \"Car\",\n",
    "#                 \"box2d\": out[\"box2d\"],\n",
    "#                 \"box3d\": refined_box,\n",
    "#                 \"score\": out[\"score\"]\n",
    "#             })\n",
    "\n",
    "#         # KITTI 형식으로 저장\n",
    "#         save_path = os.path.join(save_dir, image_id + \".txt\")\n",
    "#         with open(save_path, \"w\") as f:\n",
    "#             for det in refined_dets:\n",
    "#                 x1, y1, x2, y2 = det[\"box2d\"]\n",
    "#                 x, y, z, w, h, l, ry = det[\"box3d\"]\n",
    "#                 score = det[\"score\"]\n",
    "#                 line = f\"Car 0.00 0 -1.67 {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} \" \\\n",
    "#                        f\"{h:.2f} {w:.2f} {l:.2f} {x:.2f} {y:.2f} {z:.2f} {ry:.2f} {score:.3f}\\n\"\n",
    "                # f.write(line)\n",
    "\n",
    "    # print(f\"✅ Refined 결과 저장 완료: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06916ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_outputs(model, output_dir, kp_json_path, save_dir, iou_thresh=0.5):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    out_files = sorted(glob.glob(os.path.join(output_dir, \"*.txt\")))\n",
    "    total_boxes = 0 #\n",
    "    matched_boxes = 0 #\n",
    "    unmatched_boxes = 0 #\n",
    "\n",
    "\n",
    "    for out_path in out_files:\n",
    "        image_id = os.path.splitext(os.path.basename(out_path))[0]\n",
    "\n",
    "        # 원래 detection 결과\n",
    "        outputs = load_kitti_file(out_path, with_score=True)\n",
    "\n",
    "        total_boxes += len(outputs) #\n",
    "\n",
    "\n",
    "        if len(outputs) == 0:\n",
    "            # 비어있으면 빈 txt 저장\n",
    "            open(os.path.join(save_dir, image_id + \".txt\"), \"w\").close()\n",
    "            continue\n",
    "\n",
    "        # keypoints set\n",
    "        kp_sets = load_keypoint_json(kp_json_path, image_id)\n",
    "\n",
    "        refined_dets = []\n",
    "        for out in outputs:\n",
    "            best_match = None\n",
    "            best_iou = 0.0\n",
    "            for kp in kp_sets:\n",
    "                iou = iou_2d(out[\"box2d\"], kp[\"box2d\"])\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_match = kp\n",
    "\n",
    "            if best_match is not None and best_iou >= iou_thresh:\n",
    "                # refine 적용\n",
    "                matched_boxes += 1 #\n",
    "                init_3d = torch.tensor(out[\"box3d\"], dtype=torch.float32).unsqueeze(0)\n",
    "                keypoints = torch.tensor(best_match[\"keypoints\"], dtype=torch.float32).flatten().unsqueeze(0)\n",
    "                ry_keypoint = torch.tensor([best_match[\"ry\"]], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "                delta = model(init_3d, keypoints, ry_keypoint).detach().cpu().numpy()[0]\n",
    "                refined_box = init_3d.numpy()[0] + delta*0.3\n",
    "            else:\n",
    "                # 매칭 안되면 그대로 사용\n",
    "                unmatched_boxes += 1 #\n",
    "                refined_box = out[\"box3d\"]\n",
    "\n",
    "            refined_dets.append({\n",
    "                \"cls\": \"Car\",\n",
    "                \"box2d\": out[\"box2d\"],\n",
    "                \"box3d\": refined_box,\n",
    "                \"score\": out[\"score\"]\n",
    "            })\n",
    "\n",
    "        # KITTI 형식으로 저장\n",
    "        save_path = os.path.join(save_dir, image_id + \".txt\")\n",
    "        with open(save_path, \"w\") as f:\n",
    "            for det in refined_dets:\n",
    "                x1, y1, x2, y2 = det[\"box2d\"]\n",
    "                x, y, z, w, h, l, ry = det[\"box3d\"]\n",
    "                score = det[\"score\"]\n",
    "                line = f\"Car 0.00 0 -1.67 {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} \" \\\n",
    "                       f\"{h:.2f} {w:.2f} {l:.2f} {x:.2f} {y:.2f} {z:.2f} {ry:.2f} {score:.3f}\\n\"\n",
    "                f.write(line)\n",
    "\n",
    "    print(f\"✅ Refined 결과 저장 완료: {save_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "531f40b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Refined 결과 저장 완료: ../dataset/keypoint_refined_output_val\n",
      "====== Refinement 매칭 통계 ======\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_boxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# ✅ 최종 통계 출력\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m====== Refinement 매칭 통계 ======\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m총 박스 수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_boxes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m매칭 성공: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatched_boxes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatched_boxes\u001b[38;5;241m/\u001b[39mtotal_boxes\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m매칭 실패: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munmatched_boxes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munmatched_boxes\u001b[38;5;241m/\u001b[39mtotal_boxes\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_boxes' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. 모델 불러오기\n",
    "model = OutputKeypointRegressor(kp_dim=24)\n",
    "model.load_state_dict(torch.load(\"../outputs/regressor_best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 2. refinement 실행\n",
    "refine_outputs(\n",
    "    model,\n",
    "    output_dir=\"../dataset/merge_output_val\",\n",
    "    kp_json_path=\"../dataset/keypoints_with_theta_pred_val.json\",\n",
    "    save_dir=\"../dataset/keypoint_refined_output_val\",\n",
    "    iou_thresh=0.5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 최종 통계 출력\n",
    "print(\"====== Refinement 매칭 통계 ======\")\n",
    "print(f\"총 박스 수: {total_boxes}\")\n",
    "print(f\"매칭 성공: {matched_boxes}  ({matched_boxes/total_boxes*100:.2f}%)\")\n",
    "print(f\"매칭 실패: {unmatched_boxes}  ({unmatched_boxes/total_boxes*100:.2f}%)\")\n",
    "print(\"================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3640e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a21bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ yaw 교체 완료: ../dataset/yaw_replaced_output_val\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## theta 교체\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------\n",
    "# IoU 계산 함수 (2D)\n",
    "# ------------------------\n",
    "def iou_2d(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    return interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
    "\n",
    "# ------------------------\n",
    "# KITTI prediction 파일 로더/저장\n",
    "# ------------------------\n",
    "def load_kitti_pred_file(path):\n",
    "    dets = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 15:  # 잘못된 줄 skip\n",
    "                continue\n",
    "            cls = parts[0]\n",
    "            if cls != \"Car\":  # Car만 처리\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(float, parts[4:8])\n",
    "            h, w, l = map(float, parts[8:11])\n",
    "            x, y, z, ry = map(float, parts[11:15])\n",
    "            score = float(parts[15]) if len(parts) > 15 else 1.0\n",
    "            dets.append({\n",
    "                \"cls\": cls,\n",
    "                \"box2d\": [x1, y1, x2, y2],\n",
    "                \"box3d\": [x, y, z, w, h, l, ry],\n",
    "                \"score\": score\n",
    "            })\n",
    "    return dets\n",
    "\n",
    "def save_kitti_pred_file(path, detections):\n",
    "    with open(path, \"w\") as f:\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det[\"box2d\"]\n",
    "            x, y, z, w, h, l, ry = det[\"box3d\"]\n",
    "            score = det[\"score\"]\n",
    "            cls = det[\"cls\"]\n",
    "            truncated, occluded, alpha = 0.00, 0, -1.67\n",
    "            line = f\"{cls} {truncated:.2f} {occluded} {alpha:.2f} \" \\\n",
    "                   f\"{x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} \" \\\n",
    "                   f\"{h:.2f} {w:.2f} {l:.2f} \" \\\n",
    "                   f\"{x:.2f} {y:.2f} {z:.2f} {ry:.2f} {score:.4f}\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "# ------------------------\n",
    "# Keypoint JSON 로더\n",
    "# ------------------------\n",
    "def load_keypoints(json_path, image_id):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    kp_sets = []\n",
    "    for obj in data:\n",
    "        if obj[\"image_id\"].split(\".\")[0] != image_id:\n",
    "            continue\n",
    "        kp_sets.append({\n",
    "            \"box2d\": obj[\"crop_bbox\"],  # [x1,y1,x2,y2]\n",
    "            \"ry\": obj[\"theta\"]\n",
    "        })\n",
    "    return kp_sets\n",
    "\n",
    "# ------------------------\n",
    "# yaw 교체 함수\n",
    "# ------------------------\n",
    "def replace_yaw(output_dir, kp_json_path, save_dir, iou_thresh=0.75):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    out_files = sorted(glob.glob(os.path.join(output_dir, \"*.txt\")))\n",
    "\n",
    "    for out_path in out_files:\n",
    "        image_id = os.path.splitext(os.path.basename(out_path))[0]\n",
    "        detections = load_kitti_pred_file(out_path)\n",
    "        kp_sets = load_keypoints(kp_json_path, image_id)\n",
    "\n",
    "        for det in detections:\n",
    "            best_match = None\n",
    "            best_iou = 0.0\n",
    "            for kp in kp_sets:\n",
    "                iou = iou_2d(det[\"box2d\"], kp[\"box2d\"])\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_match = kp\n",
    "\n",
    "            if best_match is not None and best_iou >= iou_thresh:\n",
    "                # ✅ yaw 교체\n",
    "                det[\"box3d\"][-1] = best_match[\"ry\"]\n",
    "\n",
    "        save_path = os.path.join(save_dir, image_id + \".txt\")\n",
    "        save_kitti_pred_file(save_path, detections)\n",
    "\n",
    "    print(f\"✅ yaw 교체 완료: {save_dir}\")\n",
    "\n",
    "# ------------------------\n",
    "# 실행 예시\n",
    "# ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    output_dir = \"../dataset/merge_output_val\"   # MonoDGP 예측 txt\n",
    "    kp_json_path = \"../dataset/keypoints_with_theta_pred_val.json\"\n",
    "    save_dir = \"../dataset/yaw_replaced_output_val\"\n",
    "\n",
    "    replace_yaw(output_dir, kp_json_path, save_dir, iou_thresh=0.85)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d11ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84195b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cefa28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713078e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06608b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cbb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221b4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monodgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
